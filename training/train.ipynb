{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Oct  9 10:44:32 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.94                 Driver Version: 560.94         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1660 Ti   WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| 29%   42C    P8             12W /  120W |    1088MiB /   6144MiB |     17%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      1052    C+G   ...GeForce Experience\\NVIDIA Share.exe      N/A      |\n",
      "|    0   N/A  N/A      3364    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A      3792    C+G   ...617_x64__8wekyb3d8bbwe\\ms-teams.exe      N/A      |\n",
      "|    0   N/A  N/A      5548    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A      7112    C+G   ...66.0_x64__zpdnekdrzrea0\\Spotify.exe      N/A      |\n",
      "|    0   N/A  N/A      9476    C+G   ...on\\129.0.2792.79\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A      9516    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     11372    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A     11396    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     11796    C+G   ...al\\Discord\\app-1.0.9166\\Discord.exe      N/A      |\n",
      "|    0   N/A  N/A     12008    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     12432    C+G   ...\\cef\\cef.win7x64\\steamwebhelper.exe      N/A      |\n",
      "|    0   N/A  N/A     12560    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     13244    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A     14732    C+G   ...\\cef\\cef.win7x64\\steamwebhelper.exe      N/A      |\n",
      "|    0   N/A  N/A     14788    C+G   ...617_x64__8wekyb3d8bbwe\\ms-teams.exe      N/A      |\n",
      "|    0   N/A  N/A     14924    C+G   ...1.0_x64__8wekyb3d8bbwe\\Video.UI.exe      N/A      |\n",
      "|    0   N/A  N/A     15116    C+G   ...Programs\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A     15296    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A     15352    C+G   ...cal\\Microsoft\\OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A     15988    C+G   ...on\\wallpaper_engine\\wallpaper32.exe      N/A      |\n",
      "|    0   N/A  N/A     17260    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A     17560    C+G   ...on\\129.0.2792.79\\msedgewebview2.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchinfo\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer Learning of Effective Net B2 Model will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
    "effnetb2_transforms = weights.transforms()\n",
    "model = torchvision.models.efficientnet_b2(weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model will be trained on the Food 101 Dataset (~1000 images x 101 food classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75750 25250\n",
      "['apple_pie', 'baby_back_ribs', 'baklava', 'beef_carpaccio', 'beef_tartare', 'beet_salad', 'beignets', 'bibimbap', 'bread_pudding', 'breakfast_burrito', 'bruschetta', 'caesar_salad', 'cannoli', 'caprese_salad', 'carrot_cake', 'ceviche', 'cheese_plate', 'cheesecake', 'chicken_curry', 'chicken_quesadilla', 'chicken_wings', 'chocolate_cake', 'chocolate_mousse', 'churros', 'clam_chowder', 'club_sandwich', 'crab_cakes', 'creme_brulee', 'croque_madame', 'cup_cakes', 'deviled_eggs', 'donuts', 'dumplings', 'edamame', 'eggs_benedict', 'escargots', 'falafel', 'filet_mignon', 'fish_and_chips', 'foie_gras', 'french_fries', 'french_onion_soup', 'french_toast', 'fried_calamari', 'fried_rice', 'frozen_yogurt', 'garlic_bread', 'gnocchi', 'greek_salad', 'grilled_cheese_sandwich', 'grilled_salmon', 'guacamole', 'gyoza', 'hamburger', 'hot_and_sour_soup', 'hot_dog', 'huevos_rancheros', 'hummus', 'ice_cream', 'lasagna', 'lobster_bisque', 'lobster_roll_sandwich', 'macaroni_and_cheese', 'macarons', 'miso_soup', 'mussels', 'nachos', 'omelette', 'onion_rings', 'oysters', 'pad_thai', 'paella', 'pancakes', 'panna_cotta', 'peking_duck', 'pho', 'pizza', 'pork_chop', 'poutine', 'prime_rib', 'pulled_pork_sandwich', 'ramen', 'ravioli', 'red_velvet_cake', 'risotto', 'samosa', 'sashimi', 'scallops', 'seaweed_salad', 'shrimp_and_grits', 'spaghetti_bolognese', 'spaghetti_carbonara', 'spring_rolls', 'steak', 'strawberry_shortcake', 'sushi', 'tacos', 'takoyaki', 'tiramisu', 'tuna_tartare', 'waffles']\n",
      "101\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path().cwd().parent / \"data\"\n",
    "\n",
    "# Create training transforms\n",
    "train_transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.TrivialAugmentWide(),\n",
    "        effnetb2_transforms\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Get the dataset (and apply the transformations)\n",
    "train_dataset = torchvision.datasets.Food101(\n",
    "    root=data_dir,\n",
    "    split = \"train\",\n",
    "    transform=train_transforms,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.Food101(\n",
    "    root=data_dir,\n",
    "    split = \"test\",\n",
    "    transform=effnetb2_transforms,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "classes_names = train_dataset.classes\n",
    "num_of_classes = len(classes_names)\n",
    "\n",
    "print(len(train_dataset), len(test_dataset))\n",
    "print(classes_names)\n",
    "print(num_of_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data size is too big, take percentage% of both train and test\n",
    "\n",
    "def split_dataset(dataset, split_size=0.2, seed=42):\n",
    "\n",
    "    length_1 = int(len(dataset) * (1-split_size))\n",
    "    length_2 = len(dataset) - length_1\n",
    "    \n",
    "    random_split_1, random_split_2 = torch.utils.data.random_split(\n",
    "        dataset, \n",
    "        lengths=[length_1, length_2],\n",
    "        generator=torch.manual_seed(seed)\n",
    "    )\n",
    "\n",
    "    return random_split_1, random_split_2\n",
    "\n",
    "\n",
    "# subset_percentage = 0.001\n",
    "\n",
    "# _, train_dataset_subset = split_dataset(\n",
    "#     dataset=train_dataset,\n",
    "#     split_size=subset_percentage\n",
    "# )\n",
    "\n",
    "# _, test_dataset_subset = split_dataset(\n",
    "#     dataset=test_dataset,\n",
    "#     split_size=subset_percentage\n",
    "# )\n",
    "# print(len(train_dataset_subset), len(test_dataset_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2368 790\n",
      "tensor([[[[-0.3198, -0.2171,  0.0741,  ...,  1.0502,  1.0502,  1.1529],\n",
      "          [-1.1418, -0.0629,  0.3481,  ...,  1.1872,  1.1529,  1.2043],\n",
      "          [-1.3130,  0.3823,  0.7933,  ...,  1.2385,  1.1700,  1.1872],\n",
      "          ...,\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -0.9020, -0.8507, -0.9020],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -0.8849, -0.9020, -0.9363],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -0.8849, -0.8849, -0.9020]],\n",
      "\n",
      "         [[ 0.2227,  0.4153,  0.8880,  ..., -0.1275,  0.0476,  0.2752],\n",
      "          [-0.7927,  0.5903,  1.1155,  ...,  0.0126,  0.1176,  0.3102],\n",
      "          [-1.0203,  1.1331,  1.5882,  ...,  0.1352,  0.2052,  0.3627],\n",
      "          ...,\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -0.7052, -0.6702, -0.7052],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -0.7227, -0.7227, -0.7577],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -0.7577, -0.7577, -0.7752]],\n",
      "\n",
      "         [[ 1.2108,  1.3502,  1.7337,  ..., -0.3927, -0.0964,  0.1999],\n",
      "          [-0.1487,  1.5420,  1.9254,  ..., -0.2358, -0.0441,  0.2522],\n",
      "          [-0.5495,  1.9428,  2.2914,  ..., -0.0790,  0.0779,  0.3219],\n",
      "          ...,\n",
      "          [-1.8044, -1.8044, -1.8044,  ...,  0.0256,  0.0779,  0.0256],\n",
      "          [-1.8044, -1.8044, -1.8044,  ...,  0.0082, -0.0092, -0.0441],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -0.0092, -0.0441, -0.0615]]],\n",
      "\n",
      "\n",
      "        [[[-2.0494, -2.0665, -2.0837,  ..., -1.9638, -1.9295, -1.9467],\n",
      "          [-2.0837, -2.0837, -2.1008,  ..., -1.9809, -1.9638, -1.9638],\n",
      "          [-2.0837, -2.0837, -2.0837,  ..., -1.9980, -1.9809, -1.9980],\n",
      "          ...,\n",
      "          [-1.6555, -1.6213, -1.6213,  ..., -1.6898, -1.6898, -1.6898],\n",
      "          [-1.3302, -1.6555, -1.5699,  ..., -1.7069, -1.6384, -1.5870],\n",
      "          [-1.3644, -1.4500, -1.6213,  ..., -1.7412, -1.7583, -1.7240]],\n",
      "\n",
      "         [[-1.9307, -1.9482, -1.9657,  ..., -1.9132, -1.9132, -1.9307],\n",
      "          [-1.9657, -1.9657, -1.9832,  ..., -1.9307, -1.9482, -1.9482],\n",
      "          [-1.9657, -1.9657, -1.9657,  ..., -1.9482, -1.9657, -1.9832],\n",
      "          ...,\n",
      "          [-1.4755, -1.4405, -1.4405,  ..., -1.6506, -1.6506, -1.6681],\n",
      "          [-1.1429, -1.4930, -1.4055,  ..., -1.6856, -1.6331, -1.5980],\n",
      "          [-1.1779, -1.2829, -1.4580,  ..., -1.7381, -1.7556, -1.7381]],\n",
      "\n",
      "         [[-1.7522, -1.7696, -1.7870,  ..., -1.7522, -1.7347, -1.7522],\n",
      "          [-1.7870, -1.7870, -1.8044,  ..., -1.7696, -1.7696, -1.7696],\n",
      "          [-1.7870, -1.7870, -1.7870,  ..., -1.7870, -1.7870, -1.8044],\n",
      "          ...,\n",
      "          [-1.7347, -1.7173, -1.6824,  ..., -1.5430, -1.5081, -1.4907],\n",
      "          [-1.4384, -1.7522, -1.6476,  ..., -1.5604, -1.4559, -1.3687],\n",
      "          [-1.4733, -1.5256, -1.7173,  ..., -1.5953, -1.5779, -1.5081]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1872,  1.2557,  1.2557,  ...,  1.1700,  1.2899,  1.3413],\n",
      "          [ 1.2214,  1.2385,  1.2557,  ...,  1.2557,  1.4098,  1.4954],\n",
      "          [ 1.2728,  1.2385,  1.2385,  ...,  1.4440,  1.5982,  1.6495],\n",
      "          ...,\n",
      "          [-1.8097, -1.8439, -1.3302,  ..., -0.1314, -0.2171, -0.3027],\n",
      "          [-1.7925, -1.8610, -1.5357,  ..., -0.2856, -0.3883, -0.3883],\n",
      "          [-1.9124, -1.9295, -1.7583,  ..., -0.4397, -0.4739, -0.3541]],\n",
      "\n",
      "         [[ 1.4832,  1.5532,  1.5532,  ...,  1.0805,  1.2206,  1.2906],\n",
      "          [ 1.4832,  1.5182,  1.5357,  ...,  1.1856,  1.3606,  1.4482],\n",
      "          [ 1.5357,  1.5182,  1.5182,  ...,  1.3606,  1.5532,  1.5882],\n",
      "          ...,\n",
      "          [-1.5455, -1.5980, -1.0728,  ..., -1.1253, -1.2304, -1.3179],\n",
      "          [-1.5280, -1.5980, -1.2654,  ..., -1.2829, -1.3880, -1.4055],\n",
      "          [-1.6856, -1.6856, -1.5105,  ..., -1.4230, -1.4405, -1.3179]],\n",
      "\n",
      "         [[ 1.8731,  1.9428,  1.9428,  ..., -0.0092,  0.0779,  0.1128],\n",
      "          [ 1.8731,  1.9080,  1.9254,  ...,  0.0082,  0.1651,  0.2522],\n",
      "          [ 1.9254,  1.9080,  1.8905,  ...,  0.0953,  0.2871,  0.3219],\n",
      "          ...,\n",
      "          [-1.2990, -1.2990, -0.7587,  ..., -1.6476, -1.7347, -1.8044],\n",
      "          [-1.2467, -1.3164, -0.9678,  ..., -1.7696, -1.8044, -1.8044],\n",
      "          [-1.3513, -1.3687, -1.1944,  ..., -1.8044, -1.8044, -1.7347]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.6667,  1.7180,  1.7352,  ..., -0.5767, -0.6109, -0.6109],\n",
      "          [ 1.6324,  1.6667,  1.7180,  ..., -0.4568, -0.5424, -0.5424],\n",
      "          [ 1.6324,  1.6667,  1.6838,  ..., -0.3027, -0.4397, -0.4226],\n",
      "          ...,\n",
      "          [-0.7137, -0.8164, -0.9363,  ..., -1.3302, -1.3130, -1.3130],\n",
      "          [-0.8678, -0.9534, -1.0562,  ..., -1.3302, -1.2788, -1.3130],\n",
      "          [-0.9363, -0.9877, -1.1075,  ..., -1.3473, -1.2959, -1.3130]],\n",
      "\n",
      "         [[ 0.3277,  0.3803,  0.3803,  ..., -1.6856, -1.6856, -1.6856],\n",
      "          [ 0.2927,  0.3277,  0.3627,  ..., -1.6506, -1.6506, -1.6506],\n",
      "          [ 0.2927,  0.3277,  0.3452,  ..., -1.6506, -1.6331, -1.6331],\n",
      "          ...,\n",
      "          [-1.5455, -1.5805, -1.6331,  ..., -1.9657, -1.9832, -2.0007],\n",
      "          [-1.5980, -1.6331, -1.7031,  ..., -1.9482, -1.9657, -1.9832],\n",
      "          [-1.5980, -1.5980, -1.6856,  ..., -1.9657, -1.9307, -1.9482]],\n",
      "\n",
      "         [[ 1.1585,  1.2108,  1.2457,  ..., -1.0376, -1.0550, -1.0550],\n",
      "          [ 1.1237,  1.1585,  1.1759,  ..., -0.9504, -1.0027, -0.9853],\n",
      "          [ 1.1237,  1.1585,  1.1585,  ..., -0.8981, -0.9330, -0.9156],\n",
      "          ...,\n",
      "          [-1.5081, -1.5953, -1.5953,  ..., -1.7173, -1.7347, -1.7173],\n",
      "          [-1.5256, -1.5779, -1.6127,  ..., -1.7173, -1.6999, -1.6999],\n",
      "          [-1.5081, -1.5081, -1.5779,  ..., -1.7173, -1.6650, -1.6824]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1804,  2.1804,  2.1975,  ..., -0.7308, -0.7822, -0.8849],\n",
      "          [ 2.1804,  2.1975,  2.2147,  ..., -0.7650, -0.8507, -0.9534],\n",
      "          [ 2.1975,  2.2147,  2.2318,  ..., -0.8678, -0.8849, -0.9020],\n",
      "          ...,\n",
      "          [ 2.0092,  2.0092,  1.9920,  ...,  0.8618,  1.0331,  1.0844],\n",
      "          [ 1.9407,  1.9578,  1.9578,  ...,  0.9988,  1.1187,  1.2043],\n",
      "          [ 1.9920,  1.9407,  1.9407,  ...,  1.1015,  1.1187,  1.1700]],\n",
      "\n",
      "         [[ 2.0434,  2.0434,  2.0609,  ..., -0.5651, -0.6176, -0.6702],\n",
      "          [ 2.0259,  2.0434,  2.0609,  ..., -0.6001, -0.6527, -0.7402],\n",
      "          [ 1.9559,  1.9909,  2.0434,  ..., -0.6877, -0.6877, -0.6702],\n",
      "          ...,\n",
      "          [ 2.0784,  2.0434,  2.0084,  ...,  0.6429,  0.8004,  0.8354],\n",
      "          [ 2.0609,  2.0959,  2.0434,  ...,  0.7654,  0.8529,  0.9230],\n",
      "          [ 2.1485,  2.0959,  2.0784,  ...,  0.8529,  0.8354,  0.9230]],\n",
      "\n",
      "         [[ 2.0474,  2.0474,  2.0648,  ..., -0.8633, -0.9330, -1.0376],\n",
      "          [ 1.9951,  2.0125,  2.0300,  ..., -0.9156, -0.9853, -1.1073],\n",
      "          [ 1.9603,  1.9777,  2.0300,  ..., -1.0201, -1.0201, -1.0376],\n",
      "          ...,\n",
      "          [ 2.3611,  2.3437,  2.2740,  ...,  0.5311,  0.6531,  0.6879],\n",
      "          [ 2.3786,  2.3611,  2.3263,  ...,  0.6356,  0.6879,  0.7402],\n",
      "          [ 2.4483,  2.3960,  2.3786,  ...,  0.7054,  0.6531,  0.7054]]],\n",
      "\n",
      "\n",
      "        [[[-0.5082, -0.5938, -0.6794,  ..., -1.2445, -1.1760, -1.1589],\n",
      "          [-0.5082, -0.5767, -0.6623,  ..., -1.2788, -1.2103, -1.1589],\n",
      "          [-0.3883, -0.4739, -0.6109,  ..., -1.2445, -1.1418, -1.0390],\n",
      "          ...,\n",
      "          [-2.1008, -2.1008, -2.1008,  ...,  2.1975,  2.1975,  2.1633],\n",
      "          [-2.0837, -2.0837, -2.0837,  ...,  2.1975,  2.1975,  2.1804],\n",
      "          [-2.0665, -2.0665, -2.0665,  ...,  2.1975,  2.2147,  2.2147]],\n",
      "\n",
      "         [[-1.7031, -1.7031, -1.7381,  ..., -1.6506, -1.6506, -1.6681],\n",
      "          [-1.6856, -1.7031, -1.7381,  ..., -1.6856, -1.6856, -1.6681],\n",
      "          [-1.6506, -1.6856, -1.7206,  ..., -1.6856, -1.6331, -1.5980],\n",
      "          ...,\n",
      "          [-2.0182, -2.0182, -2.0182,  ..., -0.1275, -0.1800, -0.2150],\n",
      "          [-2.0007, -2.0007, -2.0007,  ..., -0.1099, -0.1625, -0.1975],\n",
      "          [-1.9832, -1.9832, -1.9832,  ..., -0.1099, -0.1450, -0.1625]],\n",
      "\n",
      "         [[-1.5604, -1.5430, -1.5604,  ..., -1.6302, -1.6127, -1.5953],\n",
      "          [-1.5430, -1.5779, -1.6127,  ..., -1.6650, -1.6302, -1.5953],\n",
      "          [-1.5256, -1.5953, -1.6476,  ..., -1.6476, -1.6127, -1.5430],\n",
      "          ...,\n",
      "          [-1.7870, -1.7870, -1.7870,  ..., -0.9504, -0.9853, -1.0201],\n",
      "          [-1.7696, -1.7696, -1.7696,  ..., -0.9504, -0.9678, -1.0027],\n",
      "          [-1.7522, -1.7522, -1.7522,  ..., -0.9504, -0.9504, -0.9678]]]])\n",
      "tensor([61, 78, 68,  8, 10,  0, 66, 34, 79, 40, 86, 49, 59, 67, 45, 45, 77, 61,\n",
      "        31, 33, 11, 32, 92, 84, 45,  2, 90, 75, 66, 50, 48, 64])\n"
     ]
    }
   ],
   "source": [
    "# Create a dataloader from the datasets\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    shuffle=True,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    shuffle=False,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(len(train_dataloader), len(test_dataloader))\n",
    "\n",
    "sample_x, sample_y = next(iter(train_dataloader))\n",
    "print(sample_x)\n",
    "print(sample_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Base model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
    "effnetb2_transforms = weights.transforms()\n",
    "model = torchvision.models.efficientnet_b2(weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze the parameters\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# change the output layer\n",
    "# print(model.classifier) # to modify only the out_features = num of classes\n",
    "model.classifier = torch.nn.Sequential(\n",
    "    torch.nn.Dropout(p=0.3, inplace=True),\n",
    "    torch.nn.Linear(\n",
    "        in_features=1408,\n",
    "        out_features=num_of_classes,\n",
    "        bias=True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPOCHS = 100\n",
    "\n",
    "\n",
    "\n",
    "# for epoch in tqdm(range(EPOCHS)):\n",
    "\n",
    "#     training_loss = 0\n",
    "#     training_acc = 0\n",
    "#     testing_loss = 0\n",
    "#     testing_acc = 0\n",
    "\n",
    "#     # Train step\n",
    "#     model.train()\n",
    "\n",
    "#     for batch_no, (X_train, y_train) in enumerate(train_dataloader):\n",
    "\n",
    "#         X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "\n",
    "#         y_logits = model(X_train)\n",
    "\n",
    "#         loss = loss_fn(y_logits, y_train)\n",
    "#         training_loss += loss\n",
    "\n",
    "#         y_pred_classes = torch.argmax(torch.softmax(y_logits, dim=1), dim=1)\n",
    "#         training_acc += (y_pred_classes == y_train).sum().item() / len(y_train)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         loss.backward()\n",
    "\n",
    "#         optimizer.step()\n",
    "\n",
    "#         if batch_no % (len(train_dataloader)//20) == 0:\n",
    "#             print(f\"Training batch {batch_no} / {len(train_dataloader)}\")\n",
    "\n",
    "#     # Evaluation step\n",
    "#     model.eval()\n",
    "\n",
    "#     with torch.no_grad():\n",
    "\n",
    "#         for X_test, y_test in test_dataloader:\n",
    "\n",
    "#             X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "#             y_logits = model(X_test)\n",
    "\n",
    "#             loss = loss_fn(y_logits, y_test)\n",
    "#             testing_loss += loss\n",
    "\n",
    "#             y_pred_classes = torch.argmax(torch.softmax(y_logits, dim=1), dim=1)\n",
    "#             testing_acc += (y_pred_classes == y_test).sum().item() / len(y_test)\n",
    "    \n",
    "#     results[\"training_loss\"] = training_loss/len(train_dataloader)\n",
    "#     results[\"training_acc\"] = training_acc/len(train_dataloader)\n",
    "#     results[\"testing_loss\"] = testing_loss/len(test_dataloader)\n",
    "#     results[\"testing_acc\"] = testing_acc/len(test_dataloader)\n",
    "\n",
    "#     print(f\"Epoch {epoch}\")\n",
    "#     print(f\"Training Loss = {results[\"training_loss\"]}  ||  Training Accuracy = {results[\"training_acc\"]}\")\n",
    "#     print(f\"Testing Loss = {results[\"testing_loss\"]}  ||  Testing Accuracy = {results[\"testing_acc\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create loss function and optimizer\n",
    "loss_fn = torch.nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = torch.optim.Adam(\n",
    "    params=model.parameters(),\n",
    "    lr=0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, train_dataloader, loss_fn, optimizer, device):\n",
    "\n",
    "    training_loss = 0\n",
    "    training_acc = 0\n",
    "\n",
    "    # Train step\n",
    "    model.train()\n",
    "\n",
    "    for batch_no, (X_train, y_train) in enumerate(train_dataloader):\n",
    "\n",
    "        X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "\n",
    "        y_logits = model(X_train)\n",
    "\n",
    "        loss = loss_fn(y_logits, y_train)\n",
    "        training_loss += loss\n",
    "\n",
    "        y_pred_classes = torch.argmax(torch.softmax(y_logits, dim=1), dim=1)\n",
    "        training_acc += (y_pred_classes == y_train).sum().item() / len(y_train)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # show rough progress\n",
    "        if batch_no % (len(train_dataloader)//20) == 0:\n",
    "            print(f\"Training batch {batch_no} / {len(train_dataloader)}\")\n",
    "\n",
    "    return training_loss/len(train_dataloader), training_acc/len(train_dataloader)\n",
    "\n",
    "\n",
    "def eval_step(model, test_dataloader, loss_fn, device):\n",
    "\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "\n",
    "    # Evaluation step\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for X_test, y_test in test_dataloader:\n",
    "\n",
    "            X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "            y_logits = model(X_test)\n",
    "\n",
    "            loss = loss_fn(y_logits, y_test)\n",
    "            test_loss += loss\n",
    "\n",
    "            y_pred_classes = torch.argmax(torch.softmax(y_logits, dim=1), dim=1)\n",
    "            test_acc += (y_pred_classes == y_test).sum().item() / len(y_test)\n",
    "    \n",
    "    return test_loss/len(test_dataloader), test_acc/len(test_dataloader)\n",
    "\n",
    "\n",
    "def train(model, train_dataloader, test_dataloader, loss_fn, optimizer, epochs = 10, device=\"cpu\"):\n",
    "\n",
    "    results = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_acc\": []\n",
    "    }\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        \n",
    "        train_loss, train_acc = train_step(\n",
    "            model=model,\n",
    "            train_dataloader=train_dataloader,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        ### Commented out eval portions on test set for quicker training\n",
    "        # test_loss, test_acc = eval_step(\n",
    "        #     model=model,\n",
    "        #     test_dataloader=test_dataloader,\n",
    "        #     loss_fn=loss_fn,\n",
    "        #     device=device\n",
    "        # )\n",
    "\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        # results[\"test_loss\"].append(test_loss)\n",
    "        # results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch}\")\n",
    "        print(f\"Train Loss = {train_loss}  ||  Training Accuracy = {train_acc}\")\n",
    "        # print(f\"Test Loss = {test_loss}  ||  Testing Accuracy = {test_acc}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [19:34<32:17:06, 1174.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Train Loss = 2.987398147583008  ||  Training Accuracy = 0.40506228885135137\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [27:03<20:21:16, 747.72s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train Loss = 2.647294282913208  ||  Training Accuracy = 0.47980011261261263\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [34:49<16:41:10, 619.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n",
      "Train Loss = 2.6233675479888916  ||  Training Accuracy = 0.4888003237612613\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [42:49<15:02:28, 564.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n",
      "Train Loss = 2.600268602371216  ||  Training Accuracy = 0.4959353885135135\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [50:23<13:50:19, 524.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n",
      "Train Loss = 2.597984552383423  ||  Training Accuracy = 0.49557027730855857\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [58:22<13:17:32, 509.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n",
      "Train Loss = 2.5890462398529053  ||  Training Accuracy = 0.4985043637387387\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [1:07:18<13:22:41, 517.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n",
      "Train Loss = 2.588693380355835  ||  Training Accuracy = 0.49927857545045046\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [1:20:05<15:15:43, 597.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n",
      "Train Loss = 2.590773582458496  ||  Training Accuracy = 0.49959089949324326\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [1:31:31<15:47:36, 624.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n",
      "Train Loss = 2.5884745121002197  ||  Training Accuracy = 0.5004838823198198\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [1:39:30<14:29:38, 579.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n",
      "Train Loss = 2.5859527587890625  ||  Training Accuracy = 0.5001627604166667\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [1:47:43<13:40:43, 553.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n",
      "Train Loss = 2.592679738998413  ||  Training Accuracy = 0.5011833122184685\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [1:54:18<12:20:50, 505.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11\n",
      "Train Loss = 2.5929808616638184  ||  Training Accuracy = 0.49947652730855857\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [2:00:30<11:13:53, 464.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12\n",
      "Train Loss = 2.5958995819091797  ||  Training Accuracy = 0.4994501337274775\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [2:06:04<10:09:38, 425.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13\n",
      "Train Loss = 2.5912129878997803  ||  Training Accuracy = 0.5010777378941441\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [2:14:18<10:31:52, 446.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14\n",
      "Train Loss = 2.5913643836975098  ||  Training Accuracy = 0.5014516469594594\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [2:22:56<10:54:48, 467.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15\n",
      "Train Loss = 2.589972972869873  ||  Training Accuracy = 0.4995425112612613\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [2:32:04<11:20:27, 491.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16\n",
      "Train Loss = 2.5971782207489014  ||  Training Accuracy = 0.4989838471283784\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [2:38:44<10:34:32, 464.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17\n",
      "Train Loss = 2.583494186401367  ||  Training Accuracy = 0.5005894566441441\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [2:47:26<10:50:01, 481.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18\n",
      "Train Loss = 2.5893170833587646  ||  Training Accuracy = 0.5021026886261262\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [2:53:45<10:00:58, 450.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19\n",
      "Train Loss = 2.586979866027832  ||  Training Accuracy = 0.5005234726914414\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [3:00:18<9:30:34, 433.35s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20\n",
      "Train Loss = 2.591038942337036  ||  Training Accuracy = 0.5006554405968469\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [3:06:33<9:00:55, 416.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21\n",
      "Train Loss = 2.5836479663848877  ||  Training Accuracy = 0.5015528223536035\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [3:14:58<9:28:05, 442.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22\n",
      "Train Loss = 2.5962612628936768  ||  Training Accuracy = 0.5000087978603603\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [3:24:00<9:58:36, 472.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23\n",
      "Train Loss = 2.590958833694458  ||  Training Accuracy = 0.5015528223536035\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [3:34:10<10:42:12, 513.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24\n",
      "Train Loss = 2.589200019836426  ||  Training Accuracy = 0.5001407657657657\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [3:43:16<10:45:38, 523.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25\n",
      "Train Loss = 2.5936081409454346  ||  Training Accuracy = 0.5014472480292792\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [3:50:21<10:00:45, 493.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26\n",
      "Train Loss = 2.592980146408081  ||  Training Accuracy = 0.49972726632882886\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [3:58:21<9:47:41, 489.74s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27\n",
      "Train Loss = 2.5886170864105225  ||  Training Accuracy = 0.501781566722973\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [4:06:48<9:45:33, 494.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28\n",
      "Train Loss = 2.5961670875549316  ||  Training Accuracy = 0.5009281742680181\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [4:14:43<9:30:32, 489.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29\n",
      "Train Loss = 2.5888659954071045  ||  Training Accuracy = 0.5004662865990991\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [4:22:58<9:24:10, 490.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30\n",
      "Train Loss = 2.591383457183838  ||  Training Accuracy = 0.5020982896959459\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [4:31:14<9:17:53, 492.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31\n",
      "Train Loss = 2.593444585800171  ||  Training Accuracy = 0.49860993806306303\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [4:37:54<8:39:00, 464.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32\n",
      "Train Loss = 2.58894681930542  ||  Training Accuracy = 0.5027053420608109\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [4:42:44<7:33:32, 412.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33\n",
      "Train Loss = 2.591463088989258  ||  Training Accuracy = 0.5003255208333333\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [4:47:17<6:41:16, 370.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34\n",
      "Train Loss = 2.5897672176361084  ||  Training Accuracy = 0.5012800886824325\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [4:52:00<6:07:04, 344.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35\n",
      "Train Loss = 2.599215030670166  ||  Training Accuracy = 0.5009589667792792\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [4:56:41<5:41:23, 325.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36\n",
      "Train Loss = 2.5903265476226807  ||  Training Accuracy = 0.5026217623873873\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [5:01:11<5:19:05, 308.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37\n",
      "Train Loss = 2.5922229290008545  ||  Training Accuracy = 0.5005718609234234\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [5:05:41<5:02:05, 297.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38\n",
      "Train Loss = 2.580693006515503  ||  Training Accuracy = 0.504786036036036\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [5:10:29<4:54:17, 294.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39\n",
      "Train Loss = 2.599186658859253  ||  Training Accuracy = 0.49851756052927926\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [5:15:05<4:44:05, 288.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40\n",
      "Train Loss = 2.593374729156494  ||  Training Accuracy = 0.5005410684121622\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42/100 [5:19:54<4:39:10, 288.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41\n",
      "Train Loss = 2.588656187057495  ||  Training Accuracy = 0.5017551731418919\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [5:26:30<5:05:06, 321.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42\n",
      "Train Loss = 2.5908803939819336  ||  Training Accuracy = 0.5005982545045046\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 44/100 [5:32:09<5:04:30, 326.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43\n",
      "Train Loss = 2.5917932987213135  ||  Training Accuracy = 0.4988650760135135\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [5:36:43<4:44:55, 310.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44\n",
      "Train Loss = 2.5939464569091797  ||  Training Accuracy = 0.4991642032657657\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [5:41:24<4:31:31, 301.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45\n",
      "Train Loss = 2.5920376777648926  ||  Training Accuracy = 0.5005762598536035\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [5:47:45<4:47:36, 325.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46\n",
      "Train Loss = 2.5843849182128906  ||  Training Accuracy = 0.5010293496621622\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 48/100 [5:52:16<4:27:53, 309.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47\n",
      "Train Loss = 2.5929226875305176  ||  Training Accuracy = 0.49981964386261263\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [5:56:36<4:10:13, 294.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48\n",
      "Train Loss = 2.5937347412109375  ||  Training Accuracy = 0.49897065033783783\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [6:00:58<3:57:17, 284.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49\n",
      "Train Loss = 2.587312698364258  ||  Training Accuracy = 0.502371023367117\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [6:05:19<3:46:35, 277.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50\n",
      "Train Loss = 2.601748466491699  ||  Training Accuracy = 0.497778540259009\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 52/100 [6:09:38<3:37:38, 272.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51\n",
      "Train Loss = 2.580698251724243  ||  Training Accuracy = 0.5029956714527027\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 53/100 [6:13:58<3:30:20, 268.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52\n",
      "Train Loss = 2.5867085456848145  ||  Training Accuracy = 0.5026173634572072\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 54/100 [6:18:19<3:24:02, 266.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53\n",
      "Train Loss = 2.598503351211548  ||  Training Accuracy = 0.4982140343468468\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [6:22:43<3:19:15, 265.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54\n",
      "Train Loss = 2.589064359664917  ||  Training Accuracy = 0.5007918074324325\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 56/100 [6:27:03<3:13:29, 263.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55\n",
      "Train Loss = 2.584109306335449  ||  Training Accuracy = 0.5013900619369369\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 57/100 [6:31:23<3:08:17, 262.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56\n",
      "Train Loss = 2.5900235176086426  ||  Training Accuracy = 0.502661352759009\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 58/100 [6:35:43<3:03:17, 261.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57\n",
      "Train Loss = 2.591618061065674  ||  Training Accuracy = 0.5027625281531531\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 59/100 [6:40:02<2:58:22, 261.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58\n",
      "Train Loss = 2.594149351119995  ||  Training Accuracy = 0.4992213893581081\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [6:44:25<2:54:19, 261.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59\n",
      "Train Loss = 2.590012550354004  ||  Training Accuracy = 0.5030792511261262\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 61/100 [6:48:44<2:49:33, 260.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60\n",
      "Train Loss = 2.5852787494659424  ||  Training Accuracy = 0.5018959389076576\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62/100 [6:53:04<2:45:00, 260.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61\n",
      "Train Loss = 2.586484670639038  ||  Training Accuracy = 0.5023666244369369\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 63/100 [6:57:24<2:40:37, 260.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62\n",
      "Train Loss = 2.595017194747925  ||  Training Accuracy = 0.5007346213400901\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 64/100 [7:01:46<2:36:30, 260.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63\n",
      "Train Loss = 2.5911850929260254  ||  Training Accuracy = 0.49981084600225223\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 65/100 [7:06:08<2:32:24, 261.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64\n",
      "Train Loss = 2.5940332412719727  ||  Training Accuracy = 0.5005542652027027\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 66/100 [7:10:30<2:28:05, 261.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65\n",
      "Train Loss = 2.588510513305664  ||  Training Accuracy = 0.5025469805743243\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 67/100 [7:14:49<2:23:26, 260.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66\n",
      "Train Loss = 2.5877816677093506  ||  Training Accuracy = 0.5009105785472973\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 68/100 [7:19:08<2:18:51, 260.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67\n",
      "Train Loss = 2.591981887817383  ||  Training Accuracy = 0.4999868032094595\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 69/100 [7:23:32<2:15:05, 261.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68\n",
      "Train Loss = 2.5920050144195557  ||  Training Accuracy = 0.5015660191441441\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70/100 [7:28:43<2:18:09, 276.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69\n",
      "Train Loss = 2.58567476272583  ||  Training Accuracy = 0.5022522522522522\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 71/100 [7:33:04<2:11:19, 271.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70\n",
      "Train Loss = 2.588812828063965  ||  Training Accuracy = 0.5029648789414414\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 72/100 [7:37:29<2:05:44, 269.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71\n",
      "Train Loss = 2.5885708332061768  ||  Training Accuracy = 0.5018959389076576\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 73/100 [7:43:34<2:14:11, 298.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72\n",
      "Train Loss = 2.5909740924835205  ||  Training Accuracy = 0.5009413710585586\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 74/100 [7:52:03<2:36:39, 361.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73\n",
      "Train Loss = 2.592223882675171  ||  Training Accuracy = 0.4998460374436937\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 75/100 [7:57:01<2:22:43, 342.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74\n",
      "Train Loss = 2.58650541305542  ||  Training Accuracy = 0.5010073550112613\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 76/100 [8:01:26<2:07:43, 319.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75\n",
      "Train Loss = 2.5861330032348633  ||  Training Accuracy = 0.5007874085022522\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 77/100 [8:05:51<1:56:09, 303.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76\n",
      "Train Loss = 2.5887465476989746  ||  Training Accuracy = 0.5011173282657657\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 78/100 [8:10:34<1:48:50, 296.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77\n",
      "Train Loss = 2.585231065750122  ||  Training Accuracy = 0.5012756897522522\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 79/100 [8:15:01<1:40:43, 287.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78\n",
      "Train Loss = 2.590750217437744  ||  Training Accuracy = 0.49950292088963966\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80/100 [8:22:28<1:51:56, 335.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79\n",
      "Train Loss = 2.5881690979003906  ||  Training Accuracy = 0.5022346565315315\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 81/100 [8:30:30<2:00:10, 379.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80\n",
      "Train Loss = 2.5803587436676025  ||  Training Accuracy = 0.5020938907657657\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 82/100 [8:37:49<1:59:11, 397.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81\n",
      "Train Loss = 2.590205192565918  ||  Training Accuracy = 0.5013592694256757\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 83/100 [8:44:40<1:53:44, 401.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82\n",
      "Train Loss = 2.5934064388275146  ||  Training Accuracy = 0.49800288569819817\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 84/100 [8:52:29<1:52:29, 421.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83\n",
      "Train Loss = 2.592562198638916  ||  Training Accuracy = 0.5021906672297297\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 85/100 [9:00:45<1:50:59, 443.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84\n",
      "Train Loss = 2.587663173675537  ||  Training Accuracy = 0.500805004222973\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 86/100 [9:05:22<1:31:56, 394.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85\n",
      "Train Loss = 2.590794563293457  ||  Training Accuracy = 0.501148120777027\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 87/100 [9:11:07<1:22:09, 379.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86\n",
      "Train Loss = 2.589655637741089  ||  Training Accuracy = 0.5001539625563063\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 88/100 [9:16:57<1:14:04, 370.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87\n",
      "Train Loss = 2.600192070007324  ||  Training Accuracy = 0.4995733037725225\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 89/100 [9:22:47<1:06:48, 364.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88\n",
      "Train Loss = 2.592317581176758  ||  Training Accuracy = 0.49958650056306303\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90/100 [9:28:08<58:32, 351.28s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89\n",
      "Train Loss = 2.5904412269592285  ||  Training Accuracy = 0.4994457347972973\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 91/100 [9:33:32<51:29, 343.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90\n",
      "Train Loss = 2.5866782665252686  ||  Training Accuracy = 0.5004003026463965\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 92/100 [9:38:57<45:02, 337.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91\n",
      "Train Loss = 2.5877132415771484  ||  Training Accuracy = 0.5022478533220721\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 93/100 [9:44:06<38:22, 328.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92\n",
      "Train Loss = 2.594637155532837  ||  Training Accuracy = 0.49942813907657657\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 94/100 [9:52:21<37:53, 378.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93\n",
      "Train Loss = 2.5995688438415527  ||  Training Accuracy = 0.49878149634009006\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 95/100 [10:02:12<36:53, 442.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94\n",
      "Train Loss = 2.5888781547546387  ||  Training Accuracy = 0.5007962063626127\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 96/100 [10:09:46<29:43, 445.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95\n",
      "Train Loss = 2.5978119373321533  ||  Training Accuracy = 0.4988254856418919\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 97/100 [10:16:29<21:39, 433.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96\n",
      "Train Loss = 2.5837390422821045  ||  Training Accuracy = 0.5010513443130631\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 98/100 [10:24:10<14:42, 441.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97\n",
      "Train Loss = 2.594062328338623  ||  Training Accuracy = 0.5001803561373873\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [10:31:54<07:28, 448.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98\n",
      "Train Loss = 2.5935919284820557  ||  Training Accuracy = 0.5008665892454954\n",
      "Training batch 0 / 2368\n",
      "Training batch 118 / 2368\n",
      "Training batch 236 / 2368\n",
      "Training batch 354 / 2368\n",
      "Training batch 472 / 2368\n",
      "Training batch 590 / 2368\n",
      "Training batch 708 / 2368\n",
      "Training batch 826 / 2368\n",
      "Training batch 944 / 2368\n",
      "Training batch 1062 / 2368\n",
      "Training batch 1180 / 2368\n",
      "Training batch 1298 / 2368\n",
      "Training batch 1416 / 2368\n",
      "Training batch 1534 / 2368\n",
      "Training batch 1652 / 2368\n",
      "Training batch 1770 / 2368\n",
      "Training batch 1888 / 2368\n",
      "Training batch 2006 / 2368\n",
      "Training batch 2124 / 2368\n",
      "Training batch 2242 / 2368\n",
      "Training batch 2360 / 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [10:41:23<00:00, 384.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99\n",
      "Train Loss = 2.588791608810425  ||  Training Accuracy = 0.5010205518018018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "results = train(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    epochs=EPOCHS,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path().cwd().parent / \"models\" / \"pretrained_effnetb2_food101.pth\"\n",
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
